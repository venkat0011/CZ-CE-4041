{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n    # convert the image to hue \n    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    # extract the green colour from the hue\n    lower_mask_hue = img_hsv [:,:,0] >= 25\n    upper_mask_hue = img_hsv [:,:,0] <= 75\n    saturation_lower = img_hsv [:,:,1] >= 40\n    saturation_upper = img_hsv[:,:,1] <= 255\n    value_lower = img_hsv[:,:,2]>= 50\n    value_upper  = img_hsv[:,:,2]<=255\n    mask = lower_mask_hue*upper_mask_hue*saturation_lower*saturation_upper*value_lower*value_upper\n    red = img_hsv[:,:,0]*mask\n    green = img_hsv[:,:,1]*mask\n    blue = img_hsv[:,:,2]*mask\n    mask = np.dstack((red,green,blue))\n    mask = cv2.normalize(mask, None, alpha=0,beta =200, norm_type=cv2.NORM_MINMAX)\n    return mask\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:26:26.721644Z","iopub.execute_input":"2022-04-13T13:26:26.722326Z","iopub.status.idle":"2022-04-13T13:26:26.730107Z","shell.execute_reply.started":"2022-04-13T13:26:26.722281Z","shell.execute_reply":"2022-04-13T13:26:26.728965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(segment_image(dataset[564]))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T13:26:26.86655Z","iopub.execute_input":"2022-04-13T13:26:26.867329Z","iopub.status.idle":"2022-04-13T13:26:27.11464Z","shell.execute_reply.started":"2022-04-13T13:26:26.86728Z","shell.execute_reply":"2022-04-13T13:26:27.113679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\nimport os\nimport cv2\nfrom glob import glob\nimages = []\nlabels = []\nfor dirname, folders,_ in os.walk('/kaggle/input/plant-seedlings-classification/train'):\n    for folder in folders:\n        path = os.path.join(dirname,folder)\n        for image_path in glob(os.path.join(path, \"*.png\")):\n            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n            image = segment_image(image)\n            image = cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)\n            images.append(image)\n            labels.append(folder)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-10T04:46:58.091886Z","iopub.execute_input":"2022-04-10T04:46:58.09232Z","iopub.status.idle":"2022-04-10T04:48:59.395054Z","shell.execute_reply.started":"2022-04-10T04:46:58.092266Z","shell.execute_reply":"2022-04-10T04:48:59.394045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change the labels to a categorical label into a numeric label \nfrom keras.utils import np_utils\nfrom sklearn import preprocessing\nlabels = pd.DataFrame(labels)\nle = preprocessing.LabelEncoder()\nle.fit(labels[0])\nencodeTrainLabels = le.transform(labels[0])\nclasses = np_utils.to_categorical(encodeTrainLabels)\nimages = np.asarray(images)\nclasses = np.asarray(classes).astype('int').reshape((4750,12))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T04:48:59.42074Z","iopub.execute_input":"2022-04-10T04:48:59.420979Z","iopub.status.idle":"2022-04-10T04:49:07.558542Z","shell.execute_reply.started":"2022-04-10T04:48:59.42095Z","shell.execute_reply":"2022-04-10T04:49:07.557418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Flatten the output layer to 1 dimension\nfrom keras import applications\nimport tensorflow as tf\nfrom keras.models import Sequential, Model \nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nmodel = tf.keras.applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n\nfor layer in model.layers[-5:]:\n    layer.trainable = False\n\nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\npredictions = Dense(12, activation=\"softmax\")(x) \n\nmodel_final = Model(model.input, predictions)\n\nmodel_final.compile(loss = \"categorical_crossentropy\", optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\nmodel_final.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-10T04:58:43.278681Z","iopub.execute_input":"2022-04-10T04:58:43.278956Z","iopub.status.idle":"2022-04-10T04:58:43.954791Z","shell.execute_reply.started":"2022-04-10T04:58:43.278925Z","shell.execute_reply":"2022-04-10T04:58:43.951302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrainX, testX, trainY, testY = train_test_split(images, classes, \n                                                test_size=0.2, random_state=2022, \n                                                stratify = classes)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T04:58:06.199885Z","iopub.execute_input":"2022-04-10T04:58:06.200257Z","iopub.status.idle":"2022-04-10T04:58:06.831251Z","shell.execute_reply.started":"2022-04-10T04:58:06.200218Z","shell.execute_reply":"2022-04-10T04:58:06.830224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        rotation_range=180,  # randomly rotate images in the range\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally\n        height_shift_range=0.1,  # randomly shift images vertically \n        horizontal_flip=True,  # randomly flip images horizontally\n        vertical_flip=True  # randomly flip images vertically\n    )  \ndatagen.fit(trainX)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T04:58:10.045332Z","iopub.execute_input":"2022-04-10T04:58:10.045702Z","iopub.status.idle":"2022-04-10T04:58:12.331883Z","shell.execute_reply.started":"2022-04-10T04:58:10.045664Z","shell.execute_reply":"2022-04-10T04:58:12.330456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.callbacks import ModelCheckpoint, EarlyStopping\n# checkpoint = ModelCheckpoint(\"vgg16_1\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\ndef callbacks():\n    \n    # save best model regularly\n    save_best_model = tf.keras.callbacks.ModelCheckpoint(filepath = 'vgg16',\n        monitor = 'val_loss', save_best_only = True, verbose = 1)\n    \n    # reduce learning rate when it stops decreasing\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor = 0.4,\n                              patience = 3, min_lr = 1e-10, verbose = 1, cooldown = 1)\n    \n    # stop training early if no further improvement\n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor = 'loss', min_delta = 1e-2, patience = 8, verbose = 1,\n        mode = 'min', baseline = None, restore_best_weights = True\n    )\n\n    return [save_best_model, reduce_lr, early_stopping]","metadata":{"execution":{"iopub.status.busy":"2022-04-10T04:58:16.660359Z","iopub.execute_input":"2022-04-10T04:58:16.660741Z","iopub.status.idle":"2022-04-10T04:58:16.670461Z","shell.execute_reply.started":"2022-04-10T04:58:16.660701Z","shell.execute_reply":"2022-04-10T04:58:16.669177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nvgghist = model_final.fit(datagen.flow(trainX,trainY),validation_data=(testX,testY), steps_per_epoch = 110, epochs = 10,callbacks = callbacks())","metadata":{"execution":{"iopub.status.busy":"2022-04-10T04:58:52.716555Z","iopub.execute_input":"2022-04-10T04:58:52.716991Z"},"trusted":true},"execution_count":null,"outputs":[]}]}