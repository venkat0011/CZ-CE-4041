{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def segment_image(image):\n    # convert the image to hue \n    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    # extract the green colour from the hue\n    lower_mask_hue = img_hsv [:,:,0] >= 25\n    upper_mask_hue = img_hsv [:,:,0] <= 75\n    saturation_lower = img_hsv [:,:,1] >= 40\n    saturation_upper = img_hsv[:,:,1] <= 255\n    value_lower = img_hsv[:,:,2]>= 50\n    value_upper  = img_hsv[:,:,2]<=255\n    mask = lower_mask_hue*upper_mask_hue*saturation_lower*saturation_upper*value_lower*value_upper\n    red = img_hsv[:,:,0]*mask\n    green = img_hsv[:,:,1]*mask\n    blue = img_hsv[:,:,2]*mask\n    mask = np.dstack((red,green,blue))\n    mask = cv2.normalize(mask, None, alpha=0,beta =200, norm_type=cv2.NORM_MINMAX)\n    return mask","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-18T02:46:57.153183Z","iopub.execute_input":"2022-04-18T02:46:57.153523Z","iopub.status.idle":"2022-04-18T02:46:57.183363Z","shell.execute_reply.started":"2022-04-18T02:46:57.153442Z","shell.execute_reply":"2022-04-18T02:46:57.182598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\nimport os\nimport cv2\nfrom glob import glob\nimages = []\nlabels = []\nfor dirname, folders,_ in os.walk('/kaggle/input/plant-seedlings-classification/train'):\n    for folder in folders:\n        path = os.path.join(dirname,folder)\n        for image_path in glob(os.path.join(path, \"*.png\")):\n            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n            image = segment_image(image)\n            image = cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)\n            images.append(image)\n            labels.append(folder)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T02:46:57.184752Z","iopub.execute_input":"2022-04-18T02:46:57.18504Z","iopub.status.idle":"2022-04-18T02:48:49.945504Z","shell.execute_reply.started":"2022-04-18T02:46:57.185012Z","shell.execute_reply":"2022-04-18T02:48:49.944548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils\nfrom sklearn import preprocessing\nlabels = pd.DataFrame(labels)\nle = preprocessing.LabelEncoder()\nle.fit(labels[0])\nencodeTrainLabels = le.transform(labels[0])\nclasses = np_utils.to_categorical(encodeTrainLabels)\nimages = np.asarray(images)\nclasses = np.asarray(classes).astype('int').reshape((4750,12))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T02:48:49.946761Z","iopub.execute_input":"2022-04-18T02:48:49.947285Z","iopub.status.idle":"2022-04-18T02:48:56.735808Z","shell.execute_reply.started":"2022-04-18T02:48:49.947242Z","shell.execute_reply":"2022-04-18T02:48:56.735157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrainX, testX, trainY, testY = train_test_split(images, classes, \n                                                test_size=0.2, random_state=2022, \n                                                stratify = classes)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T02:48:56.737512Z","iopub.execute_input":"2022-04-18T02:48:56.737868Z","iopub.status.idle":"2022-04-18T02:48:57.214012Z","shell.execute_reply.started":"2022-04-18T02:48:56.73784Z","shell.execute_reply":"2022-04-18T02:48:57.213062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\ndef load_models():\n    base_model = load_model(\"../input/resnet50-model/resmodel\")\n    base_model_1 = load_model(\"../input/model2/incep-resnetmodel/incep_resnet\")\n    base_model_2 = load_model(\"../input/model2/model.h5\")\n    base_model_3 = load_model(\"../input/model2/Resnet50_accuracy96.2/resmodel\")\n    models_array = []\n    models_array.append(base_model)\n    models_array.append(base_model_1)\n    models_array.append(base_model_2)\n    models_array.append(base_model_3)\n    return models_array\nmodels = load_models()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T02:48:57.217935Z","iopub.execute_input":"2022-04-18T02:48:57.218161Z","iopub.status.idle":"2022-04-18T02:50:08.015504Z","shell.execute_reply.started":"2022-04-18T02:48:57.218123Z","shell.execute_reply":"2022-04-18T02:50:08.014572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # we are trying to create a stacking model -> so we will predict on the train and map to the actual  label , then we will built another model to map out the function between the 3 predicted values on the actual value\ndef predict_models(models_array,trainX):\n    print(\"predicting train 1\")\n    predict_1 = models_array[0].predict((trainX))\n    predict_1 = np.argmax(predict_1, axis=1)\n    print(\"predicting train 2\")\n    predict_2 = models_array[1].predict((trainX))\n    predict_2 = np.argmax(predict_2, axis=1)\n    print(\"predicting train 3\")\n    predict_3 = models_array[2].predict((trainX))\n    predict_3 = np.argmax(predict_3, axis=1)\n    print(\"predicting train 4\")\n    predict_4 = models_array[3].predict((trainX))\n    predict_4 = np.argmax(predict_4, axis=1)\n    \n    data_frame = pd.DataFrame()\n    data_frame[\"resnet\"] = predict_1\n    data_frame[\"resnet2\"] = predict_4\n    data_frame[\"incep_resnet\"] = predict_2\n    data_frame[\"effinet\"] = predict_3\n    return data_frame\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T02:50:08.019561Z","iopub.execute_input":"2022-04-18T02:50:08.019802Z","iopub.status.idle":"2022-04-18T02:50:08.028042Z","shell.execute_reply.started":"2022-04-18T02:50:08.019774Z","shell.execute_reply":"2022-04-18T02:50:08.026933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = predict_models(models,trainX)\ntrain_data[\"true_label\"] = trainY.argmax(1)\ntest_data = predict_models(models,testX)\ntest_data[\"true_label\"] = testY.argmax(1)\ntrain_data.to_csv(\"train_rf.csv\", index=False)\ntest_data.to_csv(\"test_rf.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T02:53:21.640346Z","iopub.execute_input":"2022-04-18T02:53:21.640927Z","iopub.status.idle":"2022-04-18T03:09:40.725976Z","shell.execute_reply.started":"2022-04-18T02:53:21.640883Z","shell.execute_reply":"2022-04-18T03:09:40.725259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.incep_resnet = train_data.incep_resnet.astype('category')\ntrain_data.resnet = train_data.resnet.astype('category')\ntrain_data.true_label = train_data.true_label.astype('category')\ntrain_data.effinet = train_data.effinet.astype('category')\ntrain_data.resnet2 = train_data.resnet2.astype('category')\ntrain = train_data[[\"resnet\",\"incep_resnet\",\"effinet\",\"resnet2\"]]\nlabels = train_data.true_label\ntrain = pd.get_dummies(train)\nlabels = pd.get_dummies(labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:40.734058Z","iopub.execute_input":"2022-04-18T03:09:40.734515Z","iopub.status.idle":"2022-04-18T03:09:40.770692Z","shell.execute_reply.started":"2022-04-18T03:09:40.734477Z","shell.execute_reply":"2022-04-18T03:09:40.769812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.incep_resnet = test_data.incep_resnet.astype('category')\ntest_data.resnet = test_data.resnet.astype('category')\ntest_data.true_label = test_data.true_label.astype('category')\ntest_data.effinet = test_data.effinet.astype('category')\ntest_data.resnet2 = test_data.resnet2.astype('category')\ntest = test_data[[\"resnet\",\"incep_resnet\",\"effinet\",\"resnet2\"]]\ntest = pd.get_dummies(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:40.772958Z","iopub.execute_input":"2022-04-18T03:09:40.773718Z","iopub.status.idle":"2022-04-18T03:09:40.791588Z","shell.execute_reply.started":"2022-04-18T03:09:40.773671Z","shell.execute_reply":"2022-04-18T03:09:40.79031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# from sklearn.datasets import make_classification\n# clf = RandomForestClassifier(n_estimators = 300,random_state=42,bootstrap=True,max_features=\"auto\")\n# clf.fit(train, labels)\n\n\nfrom sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:40.793349Z","iopub.execute_input":"2022-04-18T03:09:40.793648Z","iopub.status.idle":"2022-04-18T03:09:41.025503Z","shell.execute_reply.started":"2022-04-18T03:09:40.793612Z","shell.execute_reply":"2022-04-18T03:09:41.024396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nfrom sklearn.model_selection import GridSearchCV\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV (rf, random_grid, cv = 10)\n# Fit the random search model\nrf_random.fit(train,labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:09:41.026917Z","iopub.execute_input":"2022-04-18T03:09:41.027502Z","iopub.status.idle":"2022-04-18T03:18:19.401348Z","shell.execute_reply.started":"2022-04-18T03:09:41.027453Z","shell.execute_reply":"2022-04-18T03:18:19.400246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_random.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:18:19.40301Z","iopub.execute_input":"2022-04-18T03:18:19.403368Z","iopub.status.idle":"2022-04-18T03:18:19.411371Z","shell.execute_reply.started":"2022-04-18T03:18:19.403319Z","shell.execute_reply":"2022-04-18T03:18:19.410403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve, f1_score\ntrain_predictions = rf_random.best_estimator_.predict(train)\ntrain_predictions = train_predictions.argmax(1)\nlabel = labels.to_numpy().argmax(1)\nprint(accuracy_score(train_data.true_label, train_predictions))\ntest_pred = rf_random.best_estimator_.predict(test)\ntest_pred = test_pred.argmax(1)\nprint(accuracy_score(test_data.true_label, test_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:36:52.56563Z","iopub.execute_input":"2022-04-18T03:36:52.565923Z","iopub.status.idle":"2022-04-18T03:36:53.808102Z","shell.execute_reply.started":"2022-04-18T03:36:52.565888Z","shell.execute_reply":"2022-04-18T03:36:53.807187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\nimport os\nimport cv2\nfrom glob import glob\nimages_test = []\ntestId = []\nfor image_path in glob(os.path.join(\"../input/plant-seedlings-classification/test\", \"*.png\")):\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    image = segment_image(image)\n    image = cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)\n    images_test.append(image)\n    testId.append(image_path.split('/')[-1])","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:22:34.872454Z","iopub.execute_input":"2022-04-18T03:22:34.872727Z","iopub.status.idle":"2022-04-18T03:22:45.863287Z","shell.execute_reply.started":"2022-04-18T03:22:34.8727Z","shell.execute_reply":"2022-04-18T03:22:45.862416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_test = np.asarray(images_test)\ndata_frame = predict_models(models,images_test)\ndata_frame.incep_resnet = data_frame.incep_resnet.astype('category')\ndata_frame.effinet = data_frame.effinet.astype('category')\ndata_frame.resnet = data_frame.resnet.astype('category')\ndata_frame.resnet2 = data_frame.resnet2.astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:39:28.435461Z","iopub.execute_input":"2022-04-18T03:39:28.435746Z","iopub.status.idle":"2022-04-18T03:42:10.863039Z","shell.execute_reply.started":"2022-04-18T03:39:28.435714Z","shell.execute_reply":"2022-04-18T03:42:10.862226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_frame_dummy = pd.get_dummies(data_frame)\npred = rf_random.predict(data_frame_dummy)\npred_number= np.argmax(pred, axis=1)\npredStr = le.classes_[pred_number]\n\nres = {'file': testId, 'species': predStr}\nres = pd.DataFrame(res)\nres.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T03:48:55.711619Z","iopub.execute_input":"2022-04-18T03:48:55.711906Z","iopub.status.idle":"2022-04-18T03:48:55.988639Z","shell.execute_reply.started":"2022-04-18T03:48:55.711872Z","shell.execute_reply":"2022-04-18T03:48:55.987839Z"},"trusted":true},"execution_count":null,"outputs":[]}]}