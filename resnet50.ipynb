{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# using the saturation values and hue the values we are able to segment the leafs, create a fucntion to make to do the segmentation\ndef segment_image(image):\n    # convert the image to hue \n    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    # extract the green colour from the hue\n    lower_mask_hue = img_hsv [:,:,0] >= 25\n    upper_mask_hue = img_hsv [:,:,0] <= 75\n    saturation_lower = img_hsv [:,:,1] >= 40\n    saturation_upper = img_hsv[:,:,1] <= 255\n    value_lower = img_hsv[:,:,2]>= 50\n    value_upper  = img_hsv[:,:,2]<=255\n    mask = lower_mask_hue*upper_mask_hue*saturation_lower*saturation_upper*value_lower*value_upper\n    red = img_hsv[:,:,0]*mask\n    green = img_hsv[:,:,1]*mask\n    blue = img_hsv[:,:,2]*mask\n    mask = np.dstack((red,green,blue))\n    mask = cv2.normalize(mask, None, alpha=0,beta =200, norm_type=cv2.NORM_MINMAX)\n    return mask\n    green = img_hsv[:,:,1]*mask\n    blue = img_hsv[:,:,2]*mask\n    mask = np.dstack((red,green,blue))\n    return mask","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:02:15.378357Z","iopub.execute_input":"2022-04-06T14:02:15.37903Z","iopub.status.idle":"2022-04-06T14:02:15.417164Z","shell.execute_reply.started":"2022-04-06T14:02:15.378914Z","shell.execute_reply":"2022-04-06T14:02:15.416344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\nimport os\nimport cv2\nfrom glob import glob\nimages = []\nlabels = []\nfor dirname, folders,_ in os.walk('/kaggle/input/plant-seedlings-classification/train'):\n    for folder in folders:\n        path = os.path.join(dirname,folder)\n        for image_path in glob(os.path.join(path, \"*.png\")):\n            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n            image = segment_image(image)\n            image = cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)\n            images.append(image)\n            labels.append(folder)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:02:15.501542Z","iopub.execute_input":"2022-04-06T14:02:15.502141Z","iopub.status.idle":"2022-04-06T14:04:10.927271Z","shell.execute_reply.started":"2022-04-06T14:02:15.502102Z","shell.execute_reply":"2022-04-06T14:04:10.92591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils\nfrom sklearn import preprocessing\nlabels = pd.DataFrame(labels)\nle = preprocessing.LabelEncoder()\nle.fit(labels[0])\nencodeTrainLabels = le.transform(labels[0])\nclasses = np_utils.to_categorical(encodeTrainLabels)\nimages = np.asarray(images)\nclasses = np.asarray(classes).astype('int').reshape((4750,12))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:04:10.929737Z","iopub.execute_input":"2022-04-06T14:04:10.930111Z","iopub.status.idle":"2022-04-06T14:04:18.317403Z","shell.execute_reply.started":"2022-04-06T14:04:10.93006Z","shell.execute_reply":"2022-04-06T14:04:18.316378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrainX, testX, trainY, testY = train_test_split(images, classes, \n                                                test_size=0.2, random_state=2022, \n                                                stratify = classes)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:04:18.318917Z","iopub.execute_input":"2022-04-06T14:04:18.319879Z","iopub.status.idle":"2022-04-06T14:04:18.719197Z","shell.execute_reply.started":"2022-04-06T14:04:18.31983Z","shell.execute_reply":"2022-04-06T14:04:18.718211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\n\nbase_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")\nfor layer in base_model.layers:\n    layer.trainable = False\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:04:18.72145Z","iopub.execute_input":"2022-04-06T14:04:18.721803Z","iopub.status.idle":"2022-04-06T14:04:20.931713Z","shell.execute_reply.started":"2022-04-06T14:04:18.721765Z","shell.execute_reply":"2022-04-06T14:04:20.929663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nimport tensorflow as tf\nbase_model = Sequential()\nbase_model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\nbase_model.add(Dense(1024,\"relu\"))\nbase_model.add(tf.keras.layers.Dropout(0.15))\nbase_model.add(tf.keras.layers.BatchNormalization())\nbase_model.add(Dense(12, activation='softmax'))\n\nbase_model.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:04:20.933527Z","iopub.execute_input":"2022-04-06T14:04:20.933871Z","iopub.status.idle":"2022-04-06T14:04:22.787708Z","shell.execute_reply.started":"2022-04-06T14:04:20.933827Z","shell.execute_reply":"2022-04-06T14:04:22.786442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        rotation_range=180,  # randomly rotate images in the range\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally\n        height_shift_range=0.1,  # randomly shift images vertically \n        horizontal_flip=True,  # randomly flip images horizontally\n        vertical_flip=True  # randomly flip images vertically\n    )  \ndatagen.fit(trainX)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:04:22.793421Z","iopub.execute_input":"2022-04-06T14:04:22.794789Z","iopub.status.idle":"2022-04-06T14:04:24.367699Z","shell.execute_reply.started":"2022-04-06T14:04:22.794714Z","shell.execute_reply":"2022-04-06T14:04:24.366737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef callbacks():\n    \n    # save best model regularly\n    save_best_model = tf.keras.callbacks.ModelCheckpoint(filepath = 'resnet',\n        monitor = 'val_acc', save_best_only = True, verbose = 1)\n    \n    # reduce learning rate when it stops decreasing\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor = 0.4,\n                              patience = 3, min_lr = 1e-10, verbose = 1, cooldown = 1)\n    \n    # stop training early if no further improvement\n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor = 'loss', min_delta = 1e-2, patience = 8, verbose = 1,\n        mode = 'min', baseline = None, restore_best_weights = True\n    )\n\n    return [save_best_model, reduce_lr, early_stopping]","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:08:23.213398Z","iopub.execute_input":"2022-04-06T14:08:23.21378Z","iopub.status.idle":"2022-04-06T14:08:23.22543Z","shell.execute_reply.started":"2022-04-06T14:08:23.213743Z","shell.execute_reply":"2022-04-06T14:08:23.224275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_history = base_model.fit(datagen.flow(trainX,trainY),validation_data=(testX,testY), steps_per_epoch = 100 ,epochs = 38,callbacks = callbacks())","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:08:25.812078Z","iopub.execute_input":"2022-04-06T14:08:25.812421Z","iopub.status.idle":"2022-04-06T14:10:17.263725Z","shell.execute_reply.started":"2022-04-06T14:08:25.812387Z","shell.execute_reply":"2022-04-06T14:10:17.262706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_test = []\ntestId = []\nfor image_path in glob(os.path.join(\"../input/plant-seedlings-classification/test\", \"*.png\")):\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    image = segment_image(image)\n    image = cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)\n    images_test.append(image)\n    testId.append(image_path.split('/')[-1])","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:05:54.792711Z","iopub.status.idle":"2022-04-06T14:05:54.793149Z","shell.execute_reply.started":"2022-04-06T14:05:54.792929Z","shell.execute_reply":"2022-04-06T14:05:54.79295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_test = np.asarray(images_test)\nprediction = base_model.predict(images_test)\npred_number= np.argmax(prediction, axis=1)\npredStr = le.classes_[pred_number]\nres = {'file': testId, 'species': predStr}\nres = pd.DataFrame(res)\nres.to_csv(\"res.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:05:54.810336Z","iopub.status.idle":"2022-04-06T14:05:54.810687Z","shell.execute_reply.started":"2022-04-06T14:05:54.810506Z","shell.execute_reply":"2022-04-06T14:05:54.810526Z"},"trusted":true},"execution_count":null,"outputs":[]}]}